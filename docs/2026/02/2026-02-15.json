{"executed_at":"2026-02-16T01:52:44Z","data":[{"tag":"b8067","published_at":"2026-02-15T21:31:19Z","body":"sync : ggml"},{"tag":"b8064","published_at":"2026-02-15T18:14:14Z","body":"cuda: optimize iq2xxs/iq2xs/iq3xxs dequantization (#19624)\n\n* cuda: optimize iq2xxs/iq2xs/iq3xxs dequantization\n\n- load all 8 int8 for a grid position in one load\n- calculate signs via popcnt instead of fetching from ksigns table\n- broadcast signs to drop individual shift/mask\n\n* cuda: iq2xxs: simplify sum scaling\n\nexpress `(sum * scale + sum / 2) / 4` as `(sum * (scale * 2 + 1)) / 8`\nexpress `((aux32 >> 28) * 2 + 1)` as `(aux32 >> 27 | 1)`\n\nsaves 3 registers for mul_mat_vec_q (152 -> 149) according to nsight\nAFAICT no overflow can occur here as iq2xxs values are far too small\n\n* uint -> uint32_t\n\nerror: identifier \"uint\" is undefined"},{"tag":"b8062","published_at":"2026-02-15T15:58:20Z","body":"build : remove LLAMA_HTTPLIB option (#19623)\n\nThis option was introduced as a workaround because cpp-httplib could not\nbuild on visionOS. Since it has been fixed and now compiles on all platforms,\nwe can remove it and simplify many things.\n\nSigned-off-by: Adrien GallouÃ«t <angt@huggingface.co>"},{"tag":"b8061","published_at":"2026-02-15T16:00:59Z","body":"cmake : check if KleidiAI API has been fetched (#19640)\n\nThis commit addresses a build issue with the KleidiAI backend when\nbuilding multiple cpu backends. Commmit\n3a00c98584e42a20675b6569d81beadb282b0952 (\"cmake : fix KleidiAI install\ntarget failure with EXCLUDE_FROM_ALL\") introduced a change where\nFetchContent_Populate is called instead of FetchContent_MakeAvailable,\nwhere the latter does handle this case (it is idempotent but\nFetchContent_Populate is not).\n\nI missed this during my review and I should not have commited without\nverifying the CI failure, sorry about that."},{"tag":"b8060","published_at":"2026-02-15T15:55:34Z","body":"context : fix output reorder with backend sampling (#19638)"},{"tag":"b8059","published_at":"2026-02-15T15:21:50Z","body":"ggml : avoid UB in gemm ukernel (#19642)"},{"tag":"b8058","published_at":"2026-02-15T10:56:32Z","body":"ggml-cpu: optimize ggml_vec_dot_bf16 for s390x (#19399)"},{"tag":"b8057","published_at":"2026-02-15T08:19:31Z","body":"ggml-cpu: FA add GEMM microkernel (#19422)\n\n* ggml-cpu: FA add GEMM microkernel\n\n* add guard for sizeless vector types\n\n* fix case where DV % GGML_F32_EPR !=0\n\n* move memset out of the loop\n\n* move another memset out of the loop\n\n* use RM=4 for arm\n\n* simd_gemm: convert everything to int\n\n* convert everything to size_t to avoid warnings\n\n* fixup\n\n* add pragma for ignoring aggressive loop optimizations"},{"tag":"b8056","published_at":"2026-02-15T07:16:11Z","body":"cmake : fix KleidiAI install target failure with EXCLUDE_FROM_ALL (#19581)\n\n* cmake: fix KleidiAI install target failure with EXCLUDE_FROM_ALL\n\nFix for the bug #19501 by adding EXCLUDE_FROM_ALL to FetchContent_Declare. This properly excludes KleidiAI from both build and install targets, preventing install failures when GGML_CPU_KLEIDIAI=ON is used.\n\nThe KleidiAI source files are still compiled into libggml-cpu.so, preserving all functionality.\n\n* addressed code review comments"}]}
