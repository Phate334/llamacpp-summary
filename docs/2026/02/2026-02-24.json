{"executed_at":"2026-02-25T01:52:39Z","data":[{"tag":"b8147","published_at":"2026-02-24T22:24:29Z","body":"server: fix query params lost when proxying requests in multi-model router mode (#19854)\n\n* server: fix query params lost when proxying requests in multi-model router mode\n\n* server: re-encode query params using httplib::encode_query_component in proxy"},{"tag":"b8146","published_at":"2026-02-24T21:35:23Z","body":"ggml/gguf : prevent integer overflows (#19856)\n\n* gguf : prevent integer overflow for ggml_context mem size\n\n* ggml : fix int overflows in ggml_new_object()\n\n* gguf : prevent string exhaustion\n\n* gguf : prevent array elements exhaustion\n\n* ggml : fix negative tensor type oob\n\n* py : assert that alignment is non-zero power of 2\n\n* ggml : check int overflow in ggml_new_tensor_impl and ggml_new_object\n\n* gguf-py : error on duplicate keys when reading\n\n* py : restore tensor_fields\n\n* enforce proper alignment in add_custom_alignment\n\n* gguf : better name\n\n* gguf : fix ctx size for no_alloc == true\n\n* gguf : minor print fix\n\n* ggml : print values when overflow\n\n* ggml : remove deprecated ggml_type_sizef()\n\n* ggml : relax ggml_type asserts to debug-only\n\n* gguf : add mem_size overflow test\n\n* gguf : add file size check for arrays\n\n* ggml : relax asseerts for ggml_get_type_traits()\n\n* flake8 fix\n\n---------\n\nCo-authored-by: Sigbjørn Skjæret <sigbjorn.skjaeret@scala.com>"},{"tag":"b8145","published_at":"2026-02-24T14:44:46Z","body":"model : update label for LFM2-24B-A2B (#19848)\n\n* model : Update label for LFM2-24B-A2B\n\n```\n❯ build/bin/llama-bench -m /data/playground/checkpoints/LFM2-24B-A2B-Preview-Q4_0.gguf,/data/playground/checkpoints/LFM2-8B-A1B-Q4_0.gguf -p 1 -n 0\n| model                          |       size |     params | backend    | threads |            test |                  t/s |\n| ------------------------------ | ---------: | ---------: | ---------- | ------: | --------------: | -------------------: |\n| lfm2moe 24B.A2B Q4_0           |  12.54 GiB |    23.84 B | CPU        |      10 |             pp1 |         30.35 ± 2.49 |\n| lfm2moe 8B.A1B Q4_0            |   4.41 GiB |     8.34 B | CPU        |      10 |             pp1 |         49.24 ± 1.93 |\n```\n\n* Remove extra line"},{"tag":"b8144","published_at":"2026-02-24T09:57:21Z","body":"server : support max_completion_tokens request property (#19831)\n\n\"max_tokens\" is deprectated in favor of \"max_completion_tokens\" which\nsets the upper bound for reasoning+output token.\n\nCloses: #13700"},{"tag":"b8143","published_at":"2026-02-24T08:23:48Z","body":"Vulkan Scalar Flash Attention Refactor (#19625)\n\n* vulkan: allow using fp16 in scalar flash attention shader\n\n* split rows inside of subgroups for faster synchronization\n\n* use row_split when Br >= 4, change reductions to use shared memory if row_split == 1\n\n* use f32 scalar FA if f16 is not supported by device\n\n* fix amd workgroup size issue\n\n* optimize masksh use\n\n* add medium rows FA shader Br size\n\n* fixes\n\n* add padding to mask shmem buffer\n\n* cache q values into registers for KQ\n\n* fuse lf accumulation, pf and v accumulation into a loop\n\n* stage K loads through shmem\n\n* stage V loads through shmem\n\n* only stage through shmem on Nvidia\n\n* default to Bc 32\n\n* also stage V through shmem when this is done for K\n\n* dynamic subgroups for intel\n\n* use vectorized stores\n\n* use float_type for dequantize4 functions\n\n* use smaller scalar rows size for smaller rows count\n\n* relax flash attention split_k condition to allow non-gqa use\n\n* use minimal subgroup size on Intel\n\n* fix shmem support function\n\n* fix rebase issues\n\n* fixes\n\n* Bc 4 for scalar FA is not a valid configuration\n\n* Use wave32 on AMD RDNA for scalar FA\n\n* add Intel shader core count lookup-table\n\n* fix regressions\n\n* device tuning\n\n* tmpsh size fix\n\n* fix editorconfig\n\n* refactor fa tuning logic into a single place\n\n* fix gqa opt logic\n\n* fix block_rows with small n_rows\n\n* amd tuning\n\n* fix hsk=72/80 issue\n\n* tuning\n\n* allow condition skipping for column check\n\n* use float16 for Of if available\n\n* address feedback\n\n* fix bad RDNA performance on head size <= 128 by limiting occupancy\n\n* allow printing pipeline stats\n\n* cleanup and fixes\n\n* limit occupancy for GCN for small batch FA with large HSK\n\n* disable f16 FA for GCN AMD GPUs on the proprietary driver"},{"tag":"b8142","published_at":"2026-02-24T08:03:24Z","body":"vulkan: fix coopmat1 without bf16 support (#19793)"},{"tag":"b8141","published_at":"2026-02-24T07:50:38Z","body":"vulkan: fix data race in mul_mat_id shader (#19790)"},{"tag":"b8140","published_at":"2026-02-24T02:15:00Z","body":"hexagon refactor all Ops to use local context struct (#19819)\n\n* hexagon: refactor set/get/sum-rows ops to use local context\n\n* hexagon: refactor ROPE and Softmax Ops to use local context\n\nImproves performance a bit by precomputing things and saving in the context.\n\n* hexagon: refactor activation ops to use local context struct\n\n* hexagon: refactor unary ops to use local context struct and DMA/VTCM\n\n* hexagon: use aligned hvx_scale function\n\n* hexagon: remove unused fields from op_context\n\n* hexagon: rewrite ROPE to use DMA and VTCM scratchpad\n\n* hex-rope: keep N rows in scratchpad (instead of just two)\n\n* hex-rope: introduce rowidx cache\n\n* hex-rope: remove unused fields\n\n* hex-rope: rewrite dma prefetch logic to allow for multi-row fetch/compute\n\nalso removes the need for fastdiv.\n\n* hex-rope: minor formatting\n\n* hex-rope: use indices and unroll the loops\n\n* hex-rope: more updates to cleanup rope-block handling\n\n* hexagon: cleanup supported type/dims checks\n\n* hexagon: all reduce funcs replicated across lanes\n\nThere is no need to explicitly replicate the first value.\n\n* snapdragon: update adb and windows scripts to use ubatch-size 256\n\nUpdated Ops support handles larger ubatches."}]}
