{"executed_at":"2026-02-24T01:52:42Z","data":[{"tag":"b8138","published_at":"2026-02-23T21:09:34Z","body":"vendor : update cpp-httplib to 0.34.0 (#19830)\n\nSigned-off-by: Adrien GallouÃ«t <angt@huggingface.co>"},{"tag":"b8133","published_at":"2026-02-23T06:58:47Z","body":"llama : remove write/read of output ids/logits/embeddings (#18862)\n\n* llama : remove write/read of output ids/logits/embeddings\n\nThis commit removes the write/read of output ids, logits and\nembeddings from the llama context state.\n\nRefs: https://github.com/ggml-org/llama.cpp/pull/18862#issuecomment-3756330941\n\n* completion : add replying of session state\n\nThis commit updates the session handing in the completion tool to handle\nthe that logits are no longer stored in the session file. Instead, we\nneed to replay the last token to get the logits for sampling.\n\n* common : add common_prompt_batch_decode function\n\nThis commit adds a new function which is responsible for decoding prompt\nand optionally handle the saving for session data.\n\n* update save-state.cpp to use llama_state_load_file\n\nThis commit updates the save-load-state example to utilize the new\nllama_state_load_file function for loading the model state from a file.\nAnd it also replays the last token after loading since this state is now\nstored before the last token is processed.\n\n* examples : set n_seq_max = 2 for ctx3\n\nThis commit updates the save-load-state example to set the n_seq_max\nparameter to 2 when initializing the ctx3 context.\n\nThe motivation for this change is that using 1 as n_parallel/n_seq_max\nthe context only supports one sequence, but the test laster tries to\nuse a second sequence which results in the following error:\n```console\nmain : loaded state with 4 tokens\nmain : seq 0 copied, 225760 bytes\nmain : kv cache cleared\nfind_slot: seq_id=1 >= n_seq_max=1 Try using a bigger --parallel value\nstate_read_meta: failed to find available cells in kv cache\n```\nThis seems to only happen for recurrent/hybrid models."},{"tag":"b8132","published_at":"2026-02-23T00:01:57Z","body":"cli : provide model with text filename (#19783)"}]}
