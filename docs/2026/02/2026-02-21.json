{"executed_at":"2026-02-22T01:52:32Z","data":[{"tag":"b8123","published_at":"2026-02-21T19:59:51Z","body":"Add a build target to generate ROCm artifacts using ROCm 7.2 (#19433)\n\nThis builds the following targets:\n * gfx1151\n * gfx1150\n * gfx1200\n * gfx1201\n * gfx1100\n * gfx1101\n * gfx1030\n * gfx908\n * gfx90a\n * gfx942"},{"tag":"b8122","published_at":"2026-02-21T18:41:43Z","body":"vendor : update cpp-httplib to 0.33.1 (#19778)\n\nSigned-off-by: Adrien Gallouët <adrien@gallouet.fr>"},{"tag":"b8121","published_at":"2026-02-21T11:16:15Z","body":"Improve CUDA graph capture (#19754)\n\n* Improve CUDA graph capture\n\nCurrently, CUDA graphs are eagerly enabled on the first call to ggml_backend_cuda_graph_compute. If the graph properties keep changing (4+ consecutive updates), the graph is permanently disabled. This is suboptimal because:\n\n- The first call always incurs CUDA graph capture overhead even if the graph is unstable\n- Once permanently disabled, CUDA graphs never re-enable even after the graph stabilizes (e.g., switching from prompt processing to decode)\n\nThe new approach delays CUDA graph activation until warmup completes: the same cgraph must be called at least twice with matching properties before CUDA graph capture begins. This avoids wasted capture overhead on volatile graphs and allows graphs to become eligible once they stabilize.\nThis also fixes issues such as https://github.com/ggml-org/llama.cpp/discussions/19708\n\n* Update ggml/src/ggml-cuda/ggml-cuda.cu\n\nCo-authored-by: Johannes Gäßler <johannesg@5d6.de>\n\n* Remove EM dashes\n\n* Update ggml/src/ggml-cuda/ggml-cuda.cu\n\nCo-authored-by: Aman Gupta <amangupta052@gmail.com>\n\n---------\n\nCo-authored-by: Johannes Gäßler <johannesg@5d6.de>\nCo-authored-by: Aman Gupta <amangupta052@gmail.com>"},{"tag":"b8119","published_at":"2026-02-21T02:23:32Z","body":"hexagon : fix build release (#19444) (#19587)"}]}
